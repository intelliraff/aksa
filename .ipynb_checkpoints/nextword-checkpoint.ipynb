{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bdb796d-a845-4fbc-a37d-b07c9500ce95",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h4>Importing all the stuff we need for this:</h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51543cf6-9438-44aa-804a-b708a8aa46a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 5.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting click\n",
      "  Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 5.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: joblib in ./Library/Python/3.9/lib/python/site-packages (from nltk) (1.5.2)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2026.1.15-cp39-cp39-macosx_11_0_arm64.whl (288 kB)\n",
      "\u001b[K     |████████████████████████████████| 288 kB 4.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 6.5 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: tqdm, regex, click, nltk\n",
      "Successfully installed click-8.1.8 nltk-3.9.2 regex-2026.1.15 tqdm-4.67.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abb77d7-e891-4bc3-b477-34179cec3cf1",
   "metadata": {},
   "source": [
    "<h1>START (^-^)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46ae4b6e-b624-4e2b-9705-a1ee1305ceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61481a6f-a9c9-44cb-a9ce-8cf572c94b3e",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h4>Just practicing what Tokenizer, fit_on_texts do:</h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd546060-8686-4b63-ae99-63ad98e1e4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of words in text: 44\n",
      "example has the words: {'and': 1, 'knowledge': 2, 'innovations': 3, 'technology': 4, 'are': 5, 'changing': 6, 'hence': 7, 'decision': 8}\n"
     ]
    }
   ],
   "source": [
    "text=\"\"\"\n",
    "Knowledge, innovations and technology are changing and hence decision-making in today’s social and\n",
    "business environment has become a complex task due to little or no precedents. High cost of technology,\n",
    "materials, labour, competitive pressures and so many economic, social, political factors and viewpoints, have\n",
    "greatly increase the complexity of managerial decision-making\n",
    "\"\"\"\n",
    "text=text.lower().replace(\"\\n\",\" \")\n",
    "token=Tokenizer()\n",
    "token.fit_on_texts([text])\n",
    "total_words=len(token.word_index)\n",
    "print(\"no of words in text:\",total_words)\n",
    "\n",
    "ex=\"Knowledge, innovations and technology are changing and hence decision\"\n",
    "ex=ex.lower()\n",
    "token2=Tokenizer()\n",
    "token2.fit_on_texts([ex])\n",
    "print(\"example has the words:\",token2.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b230e8e6-e514-467f-a58b-f912e91acb58",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h4>Getting the file that has contents of a book that can be\n",
    "used to train the model:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3cc2e02-e987-49f6-8a25-5e33cbae871a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT=\"\"\n",
    "filepath='Downloads/nextword/book.txt'\n",
    "with open(filepath,'r',encoding='utf-8') as book:\n",
    "    TEXT=book.read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7da9d908-38d7-4e46-8338-36f20d002677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some of the words: ['project', 'gutenbergs', 'the', 'adventures', 'of', 'sherlock', 'holmes', 'by', 'arthur', 'conan']\n",
      "No of words: 107430\n"
     ]
    }
   ],
   "source": [
    "import re                                                             #regular expressions :)\n",
    "words=re.sub(r\"[^a-zA-Z\\s]\",\"\",TEXT).split()                         # except a-z,A-Z,\\s replace everything else (^ NOT a-zA-Z\\s)\n",
    "print(\"some of the words:\",words[:10])\n",
    "print(\"No of words:\",len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7629f587-3235-46c5-9d17-41d2f5c3ecea",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h3 style=\"color:blue;\">Code starts:</h3>\n",
    "<h4>Frequency of the words,2 words together</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07904f0a-dbdb-41a9-be61-bf6fc4b94cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST REPEATED:  [('the', 5805), ('and', 3070), ('i', 2995), ('of', 2778), ('to', 2762)]\n",
      "LEAST REPEATED:  [('edition', 1), ('pg', 1), ('includes', 1), ('subscribe', 1), ('newsletter', 1)]\n",
      "\n",
      "\n",
      "MOST TOGETHER: [(('of', 'the'), 743), (('in', 'the'), 522), (('it', 'is'), 336), (('to', 'the'), 319), (('i', 'have'), 299)]\n",
      "LEAST TOGETHER: [(('email', 'newsletter'), 1), (('newsletter', 'to'), 1), (('hear', 'about'), 1), (('about', 'new'), 1)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import nltk                                            #natural language tool kit\n",
    "from nltk import bigrams\n",
    "\n",
    "\n",
    "count=Counter(words)\n",
    "#print(count.most_common())                             #gives me descending order of frequency of words\n",
    "print(\"MOST REPEATED: \",count.most_common(5))\n",
    "print(\"LEAST REPEATED: \",count.most_common()[-5:])      #idk get used to this\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "together=Counter(bigrams(words))                        #just for show no use\n",
    "print(\"MOST TOGETHER:\",together.most_common(5))\n",
    "print(\"LEAST TOGETHER:\",together.most_common()[-4:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded7475d-4e0d-4449-940b-34907e16ceff",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h4>train 5 predict 6th</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "792b1262-b688-4634-b112-a983c27238a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordstotrain=5\n",
    "input_seq=[]\n",
    "output_seq=[]\n",
    "for i in range(len(words)-wordstotrain):                                        #sliding window\n",
    "    input_seq.append(words[i:i+wordstotrain])                                   #train 5 words, predict 6th word\n",
    "    output_seq.append(words[i+wordstotrain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aa4356a6-d575-442a-b695-a25307fc93fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8600\n",
      "8601\n"
     ]
    }
   ],
   "source": [
    "Token=Tokenizer()\n",
    "Token.fit_on_texts(words)\n",
    "print(len(Token.word_index))\n",
    "total_classes=len(Token.word_index)+1\n",
    "print(total_classes)\n",
    "word_to_index=Token.word_index\n",
    "index_to_word={v: k for k, v in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "96b23a79-b707-4f54-a92f-799d9d707d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tInput sequences\n",
      "\n",
      "[['project' 'gutenbergs' 'the' 'adventures' 'of']\n",
      " ['gutenbergs' 'the' 'adventures' 'of' 'sherlock']\n",
      " ['the' 'adventures' 'of' 'sherlock' 'holmes']\n",
      " ['adventures' 'of' 'sherlock' 'holmes' 'by']\n",
      " ['of' 'sherlock' 'holmes' 'by' 'arthur']] \n",
      "\n",
      "[[ 136 4573    1  955    4]\n",
      " [4573    1  955    4  123]\n",
      " [   1  955    4  123   33]\n",
      " [ 955    4  123   33   45]\n",
      " [   4  123   33   45  524]] \n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "\t Output to be\n",
      "\n",
      "['sherlock' 'holmes' 'by' 'arthur' 'conan']\n",
      "[ 123   33   45  524 2105] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x=np.array([[Token.word_index[individual] for individual in i]for i in input_seq])\n",
    "y=np.array([Token.word_index[word] for word in output_seq])\n",
    "print(\"\\n\\tInput sequences\\n\")\n",
    "print(np.array(input_seq[:5]),\"\\n\")\n",
    "print(x[:5],\"\\n\")\n",
    "print(\"-------------------------------------\")\n",
    "print(\"\\n\\t Output to be\\n\")\n",
    "print(np.array(output_seq[:5]))\n",
    "print(y[:5],\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e58bc751-9436-4097-bf5b-aa5f63a9c828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107425, 5) (107425, 8601)\n"
     ]
    }
   ],
   "source": [
    "X=x\n",
    "Y=to_categorical(y,num_classes=total_classes)\n",
    "print(X.shape,Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5802cb4e-3602-40d0-8913-a11942dd83ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akhilasai/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer           #practice makes me remember \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,LSTM,Dropout,Embedding\n",
    "\n",
    "model=Sequential([\n",
    "    Embedding(input_dim=total_classes,output_dim=64,input_length=wordstotrain),\n",
    "    LSTM(128),\n",
    "    Dropout(0.2),\n",
    "    Dense(total_classes,activation=\"softmax\") #here we are using softmax instead of sigmoid(for 2 classes) as it has more than 2 classes\n",
    "])\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ace7d778-4b28-4acb-a357-078e5731c855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.0519 - loss: 6.9978 - val_accuracy: 0.0661 - val_loss: 6.8583\n",
      "Epoch 2/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.0685 - loss: 6.1559 - val_accuracy: 0.0808 - val_loss: 6.6726\n",
      "Epoch 3/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.0925 - loss: 5.8370 - val_accuracy: 0.1016 - val_loss: 6.5345\n",
      "Epoch 4/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.1154 - loss: 5.5578 - val_accuracy: 0.1102 - val_loss: 6.5895\n",
      "Epoch 5/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.1311 - loss: 5.3271 - val_accuracy: 0.1164 - val_loss: 6.5868\n",
      "Epoch 6/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.1406 - loss: 5.1412 - val_accuracy: 0.1207 - val_loss: 6.6585\n",
      "Epoch 7/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.1482 - loss: 4.9803 - val_accuracy: 0.1212 - val_loss: 6.7079\n",
      "Epoch 8/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.1567 - loss: 4.8278 - val_accuracy: 0.1214 - val_loss: 6.8075\n",
      "Epoch 9/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.1679 - loss: 4.6665 - val_accuracy: 0.1227 - val_loss: 6.8627\n",
      "Epoch 10/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.1738 - loss: 4.5389 - val_accuracy: 0.1245 - val_loss: 6.9287\n",
      "Epoch 11/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.1833 - loss: 4.4184 - val_accuracy: 0.1235 - val_loss: 6.9974\n",
      "Epoch 12/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.1920 - loss: 4.2840 - val_accuracy: 0.1228 - val_loss: 7.0731\n",
      "Epoch 13/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.2031 - loss: 4.1622 - val_accuracy: 0.1224 - val_loss: 7.1515\n",
      "Epoch 14/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.2156 - loss: 4.0412 - val_accuracy: 0.1206 - val_loss: 7.2666\n",
      "Epoch 15/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.2297 - loss: 3.9370 - val_accuracy: 0.1195 - val_loss: 7.3163\n",
      "Epoch 16/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.2406 - loss: 3.8348 - val_accuracy: 0.1205 - val_loss: 7.3915\n",
      "Epoch 17/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.2546 - loss: 3.7283 - val_accuracy: 0.1153 - val_loss: 7.4934\n",
      "Epoch 18/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.2681 - loss: 3.6213 - val_accuracy: 0.1175 - val_loss: 7.5466\n",
      "Epoch 19/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.2784 - loss: 3.5415 - val_accuracy: 0.1171 - val_loss: 7.6374\n",
      "Epoch 20/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.2974 - loss: 3.4384 - val_accuracy: 0.1144 - val_loss: 7.6994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x13ab839d0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,Y,epochs=20,batch_size=128,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e26011-b3bc-4d64-9c7b-270cec3ec760",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h4>Now actual prediction!!!!!</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "25e96f16-d23d-47d8-9072-81357c2b112d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not\n",
      "his\n",
      "she\n"
     ]
    }
   ],
   "source": [
    "def predict(input_sentence):\n",
    "    input_group=input_sentence.lower().split()\n",
    "    if len(input_group)!=wordstotrain:\n",
    "        raise ValueError(f\"WE NEED ONLY {wordstotrain} WORDS\")\n",
    "    else:\n",
    "        indices=[word_to_index.get(word,0) for word in input_group]\n",
    "        indices_encoded=np.array([indices])\n",
    "        PREDICTION=model.predict(indices_encoded,verbose=0)\n",
    "        index_pred=np.argmax(PREDICTION)\n",
    "        return index_to_word[index_pred]\n",
    "\n",
    "print(predict(\"A man entered who could\"))         #nahh\n",
    "print(predict(\"Boots which extended halfway up\")) #correct\n",
    "print(predict(\"he had apparently adjusted that\")) #nahh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcc1631-da7e-466d-a880-5311ca1f9dde",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h4>Some input paragraph:</h4>\n",
    "<u>A man entered who could <b>hardly</b> have been </u>less than six feet six inches\n",
    "in height, with the chest and limbs of a Hercules. His dress was rich\n",
    "with a richness which would, in England, be looked upon as akin to bad\n",
    "taste. Heavy bands of astrakhan were slashed across the sleeves and\n",
    "fronts of his double-breasted coat, while the deep blue cloak which was\n",
    "thrown over his shoulders was lined with flame-coloured silk and\n",
    "secured at the neck with a brooch which consisted of a single flaming\n",
    "beryl. <u>Boots which extended halfway up <b>his</b> calves,</u> and which were\n",
    "trimmed at the tops with rich brown fur, completed the impression of\n",
    "barbaric opulence which was suggested by his whole appearance. He\n",
    "carried a broad-brimmed hat in his hand, while he wore across the upper\n",
    "part of his face, extending down past the cheekbones, a black vizard\n",
    "mask, which <u>he had apparently adjusted that <b>very</b> moment</u>, for his hand\n",
    "was still raised to it as he entered. From the lower part of the face\n",
    "he appeared to be a man of strong character, with a thick, hanging lip,\n",
    "and a long, straight chin suggestive of resolution pushed to the length\n",
    "of obstinacy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568e0fc9-c1ae-426c-87d3-a44ae8cc5d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
